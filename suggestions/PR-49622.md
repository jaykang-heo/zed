# PR #49622: Add gemini-3.1-pro-preview model

_Merged: 2026-02-19T18:21:25Z_
_PR: https://github.com/zed-industries/zed/pull/49622_


Now let me analyze the diff more carefully to understand what model is being added and what its characteristics are:

Based on my analysis, I can now provide a comprehensive response:

## Documentation Suggestions

### Summary
The code adds a new Google AI model variant "Gemini 3.1 Pro" (`gemini-3.1-pro-preview`) with thinking mode support. This is a user-facing addition that should be documented in the AI models documentation.

### Suggested Changes

#### 1. docs/src/ai/models.md

- **Section**: Pricing table and Context Windows table
- **Change**: Add
- **Target keyword**: Gemini 3.1 Pro model pricing
- **Frontmatter**:
  ```yaml
  ---
  title: AI Models and Pricing - Zed
  description: AI models available via Zed Pro including Claude, GPT-5.2, Gemini, and Grok. Pricing, context windows, and tool call support.
  ---
  ```
- **Links**: The page already contains adequate internal links to [LLM Providers](./llm-providers.md), [Configuration](./configuration.md), [Plans and Usage](./plans-and-usage.md), and [tools](./tools.md).
- **Suggestion**: Add Gemini 3.1 Pro to the pricing and context window tables. Insert after Gemini 3 Flash entries:

In the pricing table (after row 41):
```markdown
| Gemini 3.1 Pro         | Google    | Input               | $2.00                        | $2.20                   |
|                        | Google    | Output              | $12.00                       | $13.20                  |
```

In the context windows table (after Gemini 3 Flash):
```markdown
| Gemini 3.1 Pro    | Google    | 200k                      |
```

Add to "Recent Model Retirements" section after the Gemini 2.5 lines:
```markdown
- Gemini 2.5 Pro â†’ Gemini 3 Pro or Gemini 3.1 Pro
```

Add a Preview callout at the top of the Models section (after the first paragraph):
```markdown
> **Preview:** Gemini 3.1 Pro is available in Zed Preview. It will be included in the next Stable release.
```

- **Full-file brand pass**: Required: yes. The file currently passes the brand rubric. The existing content is technically grounded (specific pricing, concrete token counts), uses natural syntax, maintains quiet confidence with facts, respects developer intelligence, prioritizes information effectively, provides specific claims, maintains consistent voice, and makes only earned claims. No additional changes needed beyond the new model addition.

- **Brand voice scorecard**:

  | Criterion            | Score | Notes |
  | -------------------- | ----- | ----- |
  | Technical Grounding  | 5/5   | Specific pricing, token counts, measurable specs |
  | Natural Syntax       | 5/5   | Tables and clear prose flow naturally |
  | Quiet Confidence     | 5/5   | States facts without hype |
  | Developer Respect    | 5/5   | Assumes competence, provides depth |
  | Information Priority | 5/5   | Pricing and specs lead, details follow |
  | Specificity          | 5/5   | Exact numbers, verifiable claims |
  | Voice Consistency    | 5/5   | Unified technical documentation tone |
  | Earned Claims        | 5/5   | All claims are factual and verifiable |
  | **TOTAL**            | 40/40 |       |

  Pass threshold: all criteria 4+.

#### 2. docs/src/ai/llm-providers.md

- **Section**: Google AI custom models section
- **Change**: Add
- **Target keyword**: configure Google AI thinking mode models
- **Frontmatter**:
  ```yaml
  ---
  title: LLM Providers - Use Your Own API Keys in Zed
  description: Bring your own API keys to Zed. Set up Anthropic, OpenAI, Google AI, Ollama, DeepSeek, Mistral, OpenRouter, and more.
  ---
  ```
- **Links**: The page already contains adequate internal links to [Agent Panel](./agent-panel.md), [Inline Assistant](./inline-assistant.md), [Text Threads](./text-threads.md), [Configuration](./configuration.md), and [plans and usage](./plans-and-usage.md). The marketing link to zed.dev is not necessary for this reference page.
- **Suggestion**: Update the custom models example in the "Google AI" section to include Gemini 3.1 Pro as an example of a thinking mode model. Replace or supplement the existing example (lines ~307-320) with:

```json [settings]
{
  "language_models": {
    "google": {
      "available_models": [
        {
          "name": "gemini-3.1-pro-preview",
          "display_name": "Gemini 3.1 Pro",
          "max_tokens": 1000000,
          "mode": {
            "type": "thinking",
            "budget_tokens": 24000
          }
        },
        {
          "name": "gemini-3-flash-preview",
          "display_name": "Gemini 3 Flash (Thinking)",
          "max_tokens": 1000000,
          "mode": {
            "type": "thinking",
            "budget_tokens": 24000
          }
        }
      ]
    }
  }
}
```

- **Full-file brand pass**: Required: yes. The file largely passes the brand rubric with a score of 36/40. Minor voice improvements needed:
  - Line ~120: "To do it via the UI" could be "Configure via the UI" (more direct)
  - Line ~294: "To use Gemini models with the Zed agent by choosing it via" could be "To use Gemini models, choose them via" (less wordy)
  - Several sections use "You can..." constructions that could be more direct commands

The file scores:
- Technical Grounding: 5/5 (specific API endpoints, exact configuration)
- Natural Syntax: 4/5 (mostly natural, some awkward constructions)
- Quiet Confidence: 5/5 (states facts clearly)
- Developer Respect: 5/5 (peer-to-peer instructions)
- Information Priority: 4/5 (mostly leads with actions, some preamble)
- Specificity: 5/5 (concrete settings, exact values)
- Voice Consistency: 4/5 (minor tonal shifts between sections)
- Earned Claims: 4/5 (all verifiable)

However, for the limited change being made (adding one example), the existing voice is acceptable and requires no additional changes beyond the model addition.

- **Brand voice scorecard** (for the new content only):

  | Criterion            | Score | Notes |
  | -------------------- | ----- | ----- |
  | Technical Grounding  | 5/5   | Exact model names, token counts, config structure |
  | Natural Syntax       | 5/5   | Clean JSON example with clear names |
  | Quiet Confidence     | 5/5   | Shows configuration without commentary |
  | Developer Respect    | 5/5   | Provides example, lets developer adapt |
  | Information Priority | 5/5   | Example leads, context already established |
  | Specificity          | 5/5   | Concrete settings with exact values |
  | Voice Consistency    | 5/5   | Matches existing examples section |
  | Earned Claims        | 5/5   | Factual configuration example |
  | **TOTAL**            | 40/40 |       |

  Pass threshold: all criteria 4+.

### Notes for Reviewer
- The Gemini 3.1 Pro model has thinking mode enabled by default based on the code (`GoogleModelMode::Thinking`), similar to Gemini 3 Pro
- The model uses the same context window (1M tokens) and max output tokens (65k) as other Gemini 3 models
- Pricing information should be confirmed with Google AI's actual pricing; I've used the same pricing as Gemini 3 Pro as a placeholder
- The Preview callout should be updated or removed when the feature ships to Stable
